# -*- coding: utf-8 -*-\n# @Time    : 2024/1/17 下午8:30\n# @Author  : sudoskys\n# @File    : infer.py\n# @Software: PyCharm\nimport logging\nimport os\nfrom pathlib import Path\nfrom typing import Dict, Union, List, Optional\nimport fasttext\nfrom robust_downloader import download\nlogger = logging.getLogger(__name__)\nMODELS = {"low_mem": None, "high_mem": None}\nFTLANG_CACHE = os.getenv("FTLANG_CACHE", "/tmp/fasttext-langdetect")\n__all__ = ["detect", "detect_multilingual"]\nclass DetectError(Exception):\n    """Custom exception for detection errors."""\n    pass\ndef get_model_map(low_memory: bool = False) -> tuple:\n    """\n    Get the model map based on the low_memory flag.\n    \":param low_memory: Flag to determine if low memory model should be used.\":return: Tuple containing mode, cache path, model name, and model URL.\":rtype: tuple\":raises Exception: If the model map cannot be determined.\